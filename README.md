# ğŸ§  Hulo Knowledge Base

> An intelligent knowledge base system for the Hulo programming language, powered by RAG (Retrieval-Augmented Generation), vector databases, and large language models.

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸŒŸ Features

- **ğŸ” Semantic Search**: Advanced vector-based document search with multi-round retrieval
- **ğŸ¤– AI-Powered Q&A**: Get intelligent answers based on Hulo documentation
- **ğŸ“š Multi-language Support**: Handle both English and Chinese documentation
- **ğŸ—ï¸ Modular Architecture**: Pluggable vector stores (Memory/ChromaDB) and LLM providers
- **âš¡ High Performance**: Async processing with FastAPI
- **ğŸ”’ Privacy-First**: Support for local LLM deployment with Ollama
- **ğŸ“Š Rich Analytics**: Document statistics and search insights
- **ğŸ› ï¸ Developer Friendly**: RESTful API with automatic documentation

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Document      â”‚    â”‚   Vector Store  â”‚    â”‚   LLM Service   â”‚
â”‚   Processor     â”‚â”€â”€â”€â–¶â”‚   (Memory/      â”‚â”€â”€â”€â–¶â”‚   (OpenAI/      â”‚
â”‚                 â”‚    â”‚    ChromaDB)    â”‚    â”‚    Ollama)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Knowledge     â”‚    â”‚   FastAPI       â”‚    â”‚   Multi-round   â”‚
â”‚   Service       â”‚â—€â”€â”€â”€â”‚   HTTP API      â”‚â—€â”€â”€â”€â”‚   Retrieval     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- [uv](https://github.com/astral-sh/uv) (recommended) or pip
- [Ollama](https://ollama.ai) (optional, for local LLM)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/hulo-knowledge-base.git
   cd hulomind
   ```

2. **Initialize the documentation submodule**
   ```bash
   git submodule update --init --recursive
   ```

3. **Install dependencies**
   ```bash
   uv sync
   ```

4. **Set up environment variables**
   ```bash
   cp env.example .env
   # Edit .env with your configuration
   ```

5. **Initialize the knowledge base**
   ```bash
   uv run python scripts/init_knowledge_base.py
   ```

6. **Start the server**
   ```bash
   uv run python -m src.main
   ```

7. **Access the API**
   - API Documentation: http://localhost:8000/docs
   - Health Check: http://localhost:8000/health

## ğŸ“– Usage

### API Endpoints

#### ğŸ” Search Documents
```bash
curl -X POST "http://localhost:8000/api/search" \
  -H "Content-Type: application/json" \
  -d '{"query": "function definition in Hulo"}'
```

#### ğŸ¤– Ask Questions
```bash
curl -X POST "http://localhost:8000/api/ask" \
  -H "Content-Type: application/json" \
  -d '{"query": "What is the difference between let and var in Hulo?"}'
```

#### ğŸ“Š Get Statistics
```bash
curl "http://localhost:8000/api/stats"
```

#### ğŸ“š List Documents
```bash
curl "http://localhost:8000/api/documents?category=grammar&language=en&limit=10"
```

### Python Client Example

```sh
uv run python -m tests.test_api
```

```python
import requests

# Search for documents
response = requests.post("http://localhost:8000/api/search", json={
    "query": "variable declaration"
})
results = response.json()
print(f"Found {results['total_results']} documents")

# Ask a question
response = requests.post("http://localhost:8000/api/ask", json={
    "query": "How do I create a function in Hulo?"
})
answer = response.json()
print(f"Answer: {answer['answer']}")
```

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `API_HOST` | API server host | `0.0.0.0` |
| `API_PORT` | API server port | `8000` |
| `DEBUG` | Enable debug mode | `false` |
| `OPENAI_API_KEY` | OpenAI API key | - |
| `DASHSCOPE_API_KEY` | Qwen API key | - |
| `DEFAULT_VECTOR_STORE` | Vector store type (`memory`/`chroma`) | `memory` |
| `CHROMA_PERSIST_DIRECTORY` | ChromaDB persistence directory | `./data/chroma` |
| `EMBEDDING_MODEL` | Sentence transformer model | `sentence-transformers/all-MiniLM-L6-v2` |
| `DOCS_PATH` | Documentation path | `./docs/src` |

### LLM Providers

The system supports multiple LLM providers with automatic fallback:

1. **OpenAI** (requires `OPENAI_API_KEY`)
2. **Qwen API** (requires `DASHSCOPE_API_KEY`)
3. **Local Ollama** (requires Ollama running with `qwen2.5:7b`)
4. **Mock Service** (fallback for testing)

### Vector Stores

- **Memory Store**: Fast, in-memory storage (default)
- **ChromaDB**: Persistent, production-ready storage

## ğŸ§ª Development

### Running Tests
```bash
uv run pytest
```

### Code Formatting
```bash
uv run black src/
uv run isort src/
```

### Type Checking
```bash
uv run mypy src/
```

### Linting
```bash
uv run ruff check src/
```

## ğŸ“ Project Structure

```
hulo-knowledge-base/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/           # Configuration management
â”‚   â”œâ”€â”€ models/           # Data models
â”‚   â”œâ”€â”€ processors/       # Document processing
â”‚   â”œâ”€â”€ vectorstore/      # Vector storage backends
â”‚   â”œâ”€â”€ services/         # Business logic services
â”‚   â”œâ”€â”€ mcp/             # MCP protocol support
â”‚   â””â”€â”€ main.py          # FastAPI application
â”œâ”€â”€ scripts/             # Utility scripts
â”œâ”€â”€ tests/               # Test suite
â”œâ”€â”€ docs/                # Documentation (submodule)
â”œâ”€â”€ data/                # Data storage
â””â”€â”€ pyproject.toml       # Project configuration
```

## ğŸ”§ Advanced Features

### Multi-round Retrieval

The system uses a sophisticated two-stage retrieval process:

1. **Broad Search**: Low threshold (0.3) to capture more candidates
2. **Refined Search**: High threshold (0.7) to filter high-quality results
3. **Merge & Deduplicate**: Combine results and remove duplicates

### Smart Document Chunking

Documents are intelligently split based on Markdown headers rather than fixed line counts, preserving semantic integrity.

### Vector Store Abstraction

```python
from src.vectorstore import VectorStoreFactory

# Use memory store
memory_store = VectorStoreFactory.create("memory")

# Use ChromaDB store
chroma_store = VectorStoreFactory.create("chroma")
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
